{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325b8a9c-848d-41f6-bfba-96b812e15768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty gefs_data array created with shape: (7304, 89, 179)\n",
      "gefs climatology created\n",
      "working on lead number 0\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 climatology created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "54\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "working on lead number 1\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "62\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "working on lead number 2\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "74\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "working on lead number 3\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "81\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "working on lead number 4\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "79\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "working on lead number 5\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "73\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "working on lead number 6\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "67\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "working on lead number 7\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "62\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "working on lead number 8\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "57\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "working on lead number 9\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "54\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "working on lead number 10\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "52\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "working on lead number 11\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "50\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "working on lead number 12\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "49\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "working on lead number 13\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "48\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "working on lead number 14\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "46\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "working on lead number 15\n",
      "gefs_data shape\n",
      "(7304, 89, 179)\n",
      "gefsanoms created\n",
      "ERA5 anomalies created, begin calculating seasonal cycle of error\n",
      "Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations\n",
      "12\n",
      "45\n",
      "Finished with spatial eofs, saving eigenvectors and eigen numbers\n",
      "Begin time-extended eofs\n",
      "Done with eofs, begin eigenmode plots\n",
      "[  0  54 116 190 271 350 423 490 552 609 663 715 765 814 862 908 953]\n",
      "The number of modes retained is 77\n",
      "Modenum = 0\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 1\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 2\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 3\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 4\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 5\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 6\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 7\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 8\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 9\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 10\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 11\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 12\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 13\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 14\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 15\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 16\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 17\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 18\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 19\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22252/2645134982.py:341: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(10,7)) #Define Figure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with figures, creating reconstructions\n",
      "Modenum = 21\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 22\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 23\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 24\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 25\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 26\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 27\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 28\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 29\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 30\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 31\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 32\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 33\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 34\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 35\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 36\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 37\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 38\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 39\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 40\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 41\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 42\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 43\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 44\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 45\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 46\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 47\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 48\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 49\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 50\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 51\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 52\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 53\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 54\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 55\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 56\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 57\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 58\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 59\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 60\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 61\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 62\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 63\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 64\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 65\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 66\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 67\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 68\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 69\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 70\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 71\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 72\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 73\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 74\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 75\n",
      "Done with figures, creating reconstructions\n",
      "Modenum = 76\n",
      "Done with figures, creating reconstructions\n",
      "Reconstruction for month 12 complete. Saving reconstruction\n"
     ]
    }
   ],
   "source": [
    "#Import Modules\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "from scipy import io as io\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeat\n",
    "import pygrib\n",
    "import urllib\n",
    "import ftplib\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "from cartopy import crs as ccrs, feature as cfeature\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.util as cutil\n",
    "\n",
    "#PREDEFINED VARIABLES\n",
    "monthi = 12 #Month used for calculations\n",
    "\n",
    "#PATHS\n",
    "\n",
    "\n",
    "nx=179\n",
    "ny=89\n",
    "ngrids=nx*ny #16380 grid size\n",
    "nleads=16 #Total number of leads\n",
    "nretained=200 #Total number of retained EOF's\n",
    "#v = np.zeros((ngrids,200, nleads,)) #This empty array will hold all spatial eigenvectors according to lead for each month\n",
    "#w = np.zeros((ngrids,nleads)) #This empty array will hold all spatial eigenvalues according to lead for each month\n",
    "W = np.zeros((ngrids,nleads))\n",
    "V = np.zeros((ngrids,nretained, nleads))\n",
    "climo_days = 382 #Used to define axis 1 of gefsclimo and ecclimo arrays. Accounts for 366 days of a year, and 16 additional forecast days\n",
    "\n",
    "#Empty arrays to store eigenvecotrs \n",
    "I80s = np.zeros((nleads)) #This empty array will be filled with the number of EOFs that explain 80% of variance according to lead for each month\n",
    "I80s_cum = np.zeros(nleads+1) #Create empty array that will store the cumulative sum of the retained EOFs for all leads\n",
    "\n",
    "#Create Date Index \n",
    "#This Date Index will be used to remove the Seasonal Cycle at different lead times\n",
    "d0=date(2000,1,1)\n",
    "d1=date(2019,12,31)\n",
    "L=(d1-d0).days\n",
    "datelist=np.array([d0+timedelta(days=int(x)) for x in np.arange((L))])\n",
    "monthlist=np.array([d.month for d in datelist])\n",
    "yearlist=np.array([d.year for d in datelist])\n",
    "daylist=np.array([d.day for d in datelist])\n",
    "Ndaysinmonthi15=np.sum(np.logical_and(monthlist==monthi,yearlist<2015))\n",
    "Ndaysinmonthi20=np.sum(np.logical_and(monthlist==monthi,yearlist>=2015))\n",
    "\n",
    "#Create list of dates that will be used for indexing in creation of gefs climatology of Z200\n",
    "doylist=np.array([(datelist[d]-date(datelist[d].year-1,12,31)).days for d in np.arange(datelist.shape[0])])\n",
    "I = np.where(doylist == 366)[0]\n",
    "doylist[I] = 365\n",
    "\n",
    "#Xarray Conversion(s)\n",
    "time = np.arange(365)\n",
    "lats = np.arange(-89,89,2) #Grid spacing will need to be redefinied to fit CPC grid spacing\n",
    "lons = np.arange(0,358,2)\n",
    "lead = np.arange(nleads)\n",
    "\n",
    "#Spacial Definitions\n",
    "latS = -88\n",
    "latN = 88\n",
    "lonW = 0\n",
    "lonE = 356\n",
    "clons = (lonW+lonE)/2.\n",
    "\n",
    "#Define the grid\n",
    "lons = np.arange(0,358, 2)\n",
    "lats = np.arange(-89,89, 2)\n",
    "dx = np.abs((lons[2]-lons[0]))\n",
    "dy = np.abs((lats[2]-lats[0]))\n",
    "dx, dy\n",
    "lonRange = np.arange(lonW, lonE + dx, dx)\n",
    "latRange = np.arange(latS, latN + dy, dy)\n",
    "proj_map = ccrs.PlateCarree(central_longitude=0)\n",
    "\n",
    "#START OF CALCULATIONS\n",
    "\n",
    "#Calculate the Seasonal Cycle, X, for gefs at each date in the above Date Index\n",
    "t=np.arange(L)\n",
    "nharm=4\n",
    "X=np.ones((L,2*nharm+1))\n",
    "for n in np.arange(nharm):\n",
    "     X[:,(n+1)*2-1]=np.sin(2*np.pi*(n+1)*t/365.25)\n",
    "     X[:,(n+1)*2]=np.cos(2*np.pi*(n+1)*t/365.25)\n",
    "\n",
    "#REFORECAST    \n",
    "#define variables to create gefs_data array shape. For 1 degree grids, change latitude and longitude accordingly. Change forecast lead to modify temporal domain\n",
    "latitude = 89 #89 gridpoints of latitude in 2x2 degree grid\n",
    "longitude = 179 #179 gridpoints of longitude in 2x2 degree grid\n",
    "#forecast_lead = 16 #16 days of forecast lead\n",
    "\n",
    "#IMPORT REFORECAST DATA for each consecutive date, for a given lead. Data is 200 hPa Geopotential Height (Z200) given in meters\n",
    "\n",
    "gefs_data=np.zeros(((d1-d0).days,latitude,longitude))\n",
    "print('empty gefs_data array created with shape: '+str(gefs_data.shape))\n",
    "\n",
    "#REANALYSIS\n",
    "#IMPORT REANALYSIS DATA. Convert to a numpy file as needed. Make sure that the latitude and longitude grid is the SAME as gefs_data\n",
    "era5data = np.load('/free2/sm957448/will_files/200mb_Z/era5_reanalysis/updated_era5data.npy')/10 #Divide by 10 to convert from meters to decameters\n",
    "era5data = era5data[:7320,:,:]\n",
    "\n",
    "#for month in np.arange(1,12,1): #Loop over all 12 months\n",
    "\n",
    "def gefs_loader(lead):\n",
    "    for d in np.arange(L): #Looping indexed days from 2000-2019 according to lead number\n",
    "        if daylist[d] == 1: #Making sure that data loading begins only when d=1 to save memory\n",
    "            if monthlist[d] < 10:\n",
    "                if lead < 10:\n",
    "                    a = np.load('/free2/sm957448/will_files/200mb_Z/gefs_reforecast/d1-10/gefs_200mbZ_110_0'+str(monthlist[d])+'.npy')\n",
    "                else:\n",
    "                    a = np.load('/free2/sm957448/will_files/200mb_Z/gefs_reforecast/d10-16/gefs_200mbZ_1016_0'+str(monthlist[d])+'.npy') \n",
    "            else: \n",
    "                if lead<10:\n",
    "                    a = np.load('/free2/sm957448/will_files/200mb_Z/gefs_reforecast/d1-10/gefs_200mbZ_110_'+str(monthlist[d])+'.npy') \n",
    "                else:\n",
    "                    a = np.load('/free2/sm957448/will_files/200mb_Z/gefs_reforecast/d10-16/gefs_200mbZ_1016_'+str(monthlist[d])+'.npy') \n",
    "                    \n",
    "        if lead < 10:\n",
    "            gefs_data[d,:,:] = a[(yearlist[d]-2000),daylist[d]-1,::-1,:,lead]\n",
    "        else:\n",
    "            gefs_data[d,:,:] = a[(yearlist[d]-2000),daylist[d]-1,::-1,:,lead-10]\n",
    "    return gefs_data/10 #Divid by ten to make decameters.\n",
    "            \n",
    "\n",
    "#Create the GEFS Climatology of the Model Variable, with the seasonal cycle removed\n",
    "def climmake(gefs_data):\n",
    "    gefsclimo = np.zeros((climo_days,gefs_data.shape[1],gefs_data.shape[2]))\n",
    "    for lead in np.arange(nleads):\n",
    "        C=np.linalg.inv(X[Iinc,:].T.dot(X[Iinc,:])).dot(X[Iinc,:].T.dot(gefs_data[Iinc,:,:].transpose(1,0,2)).transpose(1,0,2))\n",
    "        gefsclimo[:,:,:] = X.dot(C.transpose(1,0,2))[:gefsclimo.shape[0],:gefsclimo.shape[1],:]\n",
    "    return gefsclimo\n",
    "print('gefs climatology created')\n",
    "\n",
    "for lead in np.arange(nleads):            \n",
    "    #Perform Quality control on gefs_data by indexing days with missing data across all days and leads\n",
    "    print('working on lead number ' +str(lead))\n",
    "    #gefs_data=gefs_loader(lead) #Function which loads and creates gefs_data files as a .npy\n",
    "    #np.save('/free2/sm957448/will_files/200mb_Z/gefs_data/gefs_data_lead'+str(lead)+'.npy', gefs_data)\n",
    "    gefs_data=np.load('/free2/sm957448/will_files/200mb_Z/gefs_data/gefs_data_lead'+str(lead)+'.npy') #Loads saved gefs_data files as a .npy\n",
    "    #print(gefs_data)\n",
    "    print('gefs_data shape')\n",
    "    print(gefs_data.shape)\n",
    "    A=np.sum(gefs_data==0,axis=2)\n",
    "    A=np.sum(A>0,axis=1)\n",
    "    Iexc = np.where(A>0)[0] #Index of days that are excluded because they have missing data\n",
    "    Iinc = np.where(A==0)[0] #Index of days that are included, no missing data\n",
    "    \n",
    "    #Calculate the seasonal cycle, X, for each date\n",
    "    t=np.arange(L)\n",
    "    nharm=4 #4 harmonics of the seasonal cycle will be removed\n",
    "    X=np.ones((L,2*nharm+1)) #X represents the seasonal cycle of data\n",
    "    for n in np.arange(nharm):\n",
    "        X[:,(n+1)*2-1]=np.sin(2*np.pi*(n+1)*t/365.25) \n",
    "        X[:,(n+1)*2]=np.cos(2*np.pi*(n+1)*t/365.25)\n",
    "\n",
    "    #Create gefs error anomalies by subtracting the climatology\n",
    "    gefsanoms = np.zeros((gefs_data.shape))\n",
    "    #gefsclimo=climmake(gefs_data)\n",
    "    #np.save('/free2/sm957448/will_files/200mb_Z/gefs_climo/gefs_climo_lead'+str(lead)+'.npy', gefsclimo)\n",
    "    gefsclimo=np.load('/free2/sm957448/will_files/200mb_Z/gefs_climo/gefs_climo_lead'+str(lead)+'.npy') #Loads saved gefs_climo files as a .npy\n",
    "    \n",
    "    gefsanoms[Iinc,:,:] = (((gefs_data[Iinc,:,:]-gefsclimo[doylist[Iinc],:,:])))\n",
    "    print('gefsanoms created')\n",
    "\n",
    "    #Adjust date objects to reflect the additional 16 days of forecast lead\n",
    "    d0=date(2000,1,1)\n",
    "    d1=date(2020,1,16)\n",
    "    L=(d1-d0).days\n",
    "    datelist=np.array([d0+timedelta(days=int(x)) for x in np.arange((L))])\n",
    "    monthlist=np.array([d.month for d in datelist])\n",
    "    yearlist=np.array([d.year for d in datelist])\n",
    "    daylist=np.array([d.day for d in datelist])\n",
    "\n",
    "    #Create list of dates that will be used for indexing in creation of era5 anomalies\n",
    "    doylist=np.array([(datelist[d]-date(datelist[d].year-1,12,31)).days for d in np.arange(datelist.shape[0])])\n",
    "    I = np.where(doylist == 366)[0]\n",
    "    doylist[I] = 365\n",
    "\n",
    "    #Create the ERA5 Climatology of the Model Variable, with the seasonal cycle removed\n",
    "    era5anoms = np.zeros((era5data.shape)) #Import will need to be recalulated in order to fit CPC CFS data set, make sure the shapes of gefs_data and CFS match the appropriate arrays\n",
    "    if lead == 0:\n",
    "        #ecclimo=climmake(era5data)\n",
    "        #np.save('/free2/sm957448/will_files/200mb_Z/ecclimo/ecclimo.npy', ecclimo)\n",
    "        ecclimo=np.load('/free2/sm957448/will_files/200mb_Z/ecclimo/ecclimo.npy')\n",
    "        print('ERA5 climatology created')\n",
    "        #Create ERA5 anomalies by subtracting the climatology\n",
    "        era5anoms[Iinc,:,:] = (era5data[Iinc,:,:]-ecclimo[doylist[Iinc],:,:])\n",
    "        np.save('/free2/sm957448/will_files/200mb_Z/era5anoms/era5anoms.npy',era5anoms)\n",
    "    else:\n",
    "        era5anoms=np.load('/free2/sm957448/will_files/200mb_Z/era5anoms/era5anoms.npy')\n",
    "        \n",
    "    print('ERA5 anomalies created, begin calculating seasonal cycle of error')\n",
    "    #CALCULATE AND PLOT MODEL SEASONAL CYCLE OF ERROR\n",
    "\n",
    "    #Dispose of climatology arrays to save memory\n",
    "    ecclimo = []\n",
    "    gefsclimo = []\n",
    "\n",
    "    #CALCULATE TOTAL ERROR ANOMALIES\n",
    "    #Subtract the era5 anomalies from gefsanomalies according to lead \n",
    "    erroranoms=np.zeros((era5data.shape[0],gefs_data.shape[1], gefs_data.shape[2]))\n",
    "    #for lead in np.arange(nleads): #Fill the array\n",
    "    erroranoms[Iinc,:,:] = (((gefsanoms[Iinc,:,:]-era5anoms[Iinc+lead,:,:])))\n",
    "    print('Total Error Anomalies Created. Beginning Spatial Eigenvector Calculations')\n",
    "\n",
    "    #Dispose of unnecessary arrays to save memory\n",
    "    #era5data = []\n",
    "    era5anoms = []\n",
    "\n",
    "    #NOW WE BEGIN THE STATISTICAL POSTPROCESSING ALGORITHM\n",
    "    #Reset the Date Indexing one final time to return to the original 7304 day temporal domain, which erroranoms and gefsanoms abide by\n",
    "    d0=date(2000,1,1)\n",
    "    d1=date(2019,12,31)\n",
    "    L=(d1-d0).days\n",
    "    datelist=np.array([d0+timedelta(days=int(x)) for x in np.arange((L))])\n",
    "    monthlist=np.array([d.month for d in datelist])\n",
    "    yearlist=np.array([d.year for d in datelist])\n",
    "    daylist=np.array([d.day for d in datelist])\n",
    "\n",
    "    #Create monthly indexing to run the two-step EOF algorithm according to each month \n",
    "    #for month in np.arange(11,12,1):\n",
    "    Imonths = np.where(monthlist==monthi)[0] #Create Indexing for the days in each month over the 20 year period, with all dates that contain missing data removed\n",
    "    print(monthi)\n",
    "    Xmonths = np.zeros((Imonths.shape[0],latitude*longitude)) #This empty array will be used to store spatial GEFSv12 data based on total error anomaly (erroranoms) data\n",
    "    Xmonths_a = np.zeros((Imonths.shape[0],latitude*longitude)) #This empty array will be used store GEFSv12 anomaly (gefsanoms) data. The \"a\" stands for approximate, and will be used to create the reconstructions\n",
    "    I15 = np.where(yearlist[Imonths] == 2015)[0][0] #I15 represents the index number of 1/1/15, when the training set turns into the testing set\n",
    "    Inm_reindex = np.where(np.logical_and(yearlist[Imonths]<2015, gefsanoms[Imonths,10,10] != 0))[0] #Inm_reindex reindexes the dates of the training set to exclude missing dates, different from Iinc because it solely is for the training set.\n",
    "    Imonths15 = Imonths[:I15] #Imonths15 is the index of dates of the selected months from 1/1/00 - 1/1/15\n",
    "    Imonths20 = Imonths[I15:] #Imonths20 is the index of dates for the selected months from 1/1/15-12/31/19\n",
    "    Xmonths15 = Xmonths[:I15,:] #Xmonths15 is the data matrix of the geopotential height erroranomalies up to 1/1/15\n",
    "    Xmonths20 = Xmonths[I15:,:] #Xmonths20 is the data matrix of geopotential height error anomalies from 1/1/15-12/31/19\n",
    "    Xmonths20_a = Xmonths_a[I15:,:] #Xmonths20_a is the data matrix of reconstructed geopotential height error anomalies from 1/1/15 - 12/31/19\n",
    "\n",
    "        #lats = np.arange(-89,89,2) #Define the 2 degree latitude range. Used to help account for curvature of earth at high latitudes\n",
    "#    w_spec = np.zeros((Xmonths15.shape[1],gefs_data.shape[3])) #This empty array will create the normalized eigenvalues (may be commented out)\n",
    "    \n",
    "    #Create Spatial EOFs\n",
    "    #for lead in np.arange(nleads):\n",
    "    for y in np.arange(latitude):\n",
    "        Xmonths15[:,(y*longitude):((y+1)*longitude)] = erroranoms[Imonths15,y,:]*np.sqrt(np.cos((lats[y]*2*np.pi)/360)) #Fill Xmonths15 with training data\n",
    "        Xmonths20[:,(y*longitude):((y+1)*longitude)] = erroranoms[Imonths20,y,:]*np.sqrt(np.cos((lats[y]*2*np.pi)/360)) #Fill Xmonths20 with training data\n",
    "        Xmonths20_a[:,(y*longitude):((y+1)*longitude)] = gefsanoms[Imonths20,y,:]*np.sqrt(np.cos((lats[y]*2*np.pi)/360)) #Fill Xmonths20_a with testing data\n",
    "    Cov = (Xmonths15[Inm_reindex,:].T.dot(Xmonths15[Inm_reindex,:]))/Xmonths15[Inm_reindex,:].shape[0] #Covariance matrix for spatial eigenvectors for training period\n",
    "    w,v = np.linalg.eigh(Cov) #Calculate monthly eigenvectors and eigenvalues\n",
    "    w=w.real\n",
    "    v=v.real\n",
    "    Isort=np.argsort(-w) #Sorting index numbers\n",
    "    w=w[Isort]\n",
    "    v=v[:,Isort]\n",
    "    W[:,lead]=w\n",
    "    V[:,:,lead]=v[:,:nretained]\n",
    "        \n",
    "        \n",
    "    w=w/w.sum() #normalize the eigenvalues to create an eigenspectrum\n",
    "    I80 = np.where(np.cumsum(w)>.8)[0][0] #Retain the EOFs that explain 80% of the variance\n",
    "    I80s[lead] = I80 #Store retained EOFs according to lead \n",
    "    print(I80)\n",
    "        \n",
    "    #Create Time Extended EOFs\n",
    "    for y in np.arange(latitude):\n",
    "        Xmonths15[:,(y*longitude):((y+1)*longitude)] = erroranoms[Imonths15,y,:]*np.sqrt(np.cos((lats[y]*2*np.pi)/360))\n",
    "        Xmonths20[:,(y*longitude):((y+1)*longitude)] = erroranoms[Imonths20,y,:]*np.sqrt(np.cos((lats[y]*2*np.pi)/360))\n",
    "        Xmonths20_a[:,(y*longitude):((y+1)*longitude)] = gefsanoms[Imonths20,y,:]*np.sqrt(np.cos((lats[y]*2*np.pi)/360))\n",
    "    if lead == 0:\n",
    "        PC=np.zeros((Xmonths15.shape[0],nretained,nleads))\n",
    "        PC20_a=np.zeros((Xmonths20_a.shape[0],nretained,nleads))\n",
    "    PC[:,:,lead] = Xmonths15[:,:].dot(V[:,:nretained,lead]) #Project retainedspatial eigenvectors onto training data according to lead \n",
    "    PC20_a[:,:,lead] = Xmonths20_a[:,:].dot(V[:,:nretained,lead]) #Project retainedspatial eigenvectors onto testing data according to lead\n",
    "\n",
    "        \n",
    "    print('Finished with spatial eofs, saving eigenvectors and eigen numbers')\n",
    "    # np.save('/free2/sm957448/200mb_Z/full_eigenvectors/w12_not_std.npy', w)\n",
    "    # np.save('/free2/sm957448/200mb_Z/full_eigenvectors/v12.npy', v)\n",
    "    # np.save('/free2/sm957448/200mb_Z/full_eigenvectors/I80s/I80s_12.npy', I80s)\n",
    "    \n",
    "    print('Begin time-extended eofs')\n",
    "#Now we calculate and store the spatial PCs\n",
    "I80s_cum[1:17] = np.cumsum(I80s) #Store the cumulative sum of the EOFs that explain 80% of the varinace. These will be used to create the time extended data arrays\n",
    "I80s_cum = I80s_cum.astype(int)\n",
    "#Create empty arrays for the time extended EOFs to be filled later.\n",
    "X_ext = np.zeros((Xmonths15.shape[0],int(np.sum(I80s))))\n",
    "X_ext20_a = np.zeros((Xmonths20_a.shape[0],int(np.sum(I80s))))\n",
    "    \n",
    "\n",
    "for lead in np.arange(nleads):    \n",
    "    X_ext[:,int(I80s_cum[lead]):int(I80s_cum[lead+1])] = PC[:,:int(I80s[lead]),lead] #Fill time extended training array with spatial PCs for time extended EOFs\n",
    "    X_ext20_a[:,int(I80s_cum[lead]):int(I80s_cum[lead+1])] = PC20_a[:,:int(I80s[lead]),lead] #Fill time extended testing array with spatial PCs for time extended EOFs\n",
    "            \n",
    "#Now that we have the time extended X matrices, we restart the EOF process, this time using the time extended matrixes\n",
    "#Find the time extended covariance matrix:\n",
    "Cov = (X_ext[Inm_reindex,:].T.dot(X_ext[Inm_reindex,:]))/X_ext[Inm_reindex,:].shape[0] #Define covariance matrix for time extended EOfs\n",
    "\n",
    "#Find eigenvalues and eigenvectors of Cov\n",
    "w_ext, v_ext = np.linalg.eigh(Cov) #Calculate time extended eigenvectors and eigenvalues\n",
    "w_ext = w_ext.real\n",
    "v_ext = v_ext.real\n",
    "\n",
    "#Time extended Eigenspectrum (standardizing the eigenvalues)\n",
    "w_ext = w_ext/w_ext.sum()\n",
    "\n",
    "#Create index for sorted time extended eigenvalues. Use index when sorting eigenvectors\n",
    "I = np.argsort(-w_ext)\n",
    "w_ext = w_ext[I]\n",
    "v_ext = v_ext[:,I]\n",
    "# np.save('/pr11/ws347875/200mb_Z/full_eigenvectors/time_extended/Vext_12.npy', v_ext)\n",
    "# np.save('/pr11/ws347875/200mb_Z/full_eigenvectors/time_extended/Wext_12.npy', w_ext)\n",
    "\n",
    "print('Done with eofs, begin eigenmode plots')\n",
    "    \n",
    "#CREATE EIGENMODE PLOTS\n",
    "\n",
    "#Define N (previously known as I80) based off of I80s\n",
    "N = np.zeros(17).astype(int)\n",
    "N[1:] = np.cumsum(I80s).astype(int)\n",
    "print(N)\n",
    "leads=np.arange(nleads)\n",
    "#Prepare indexing and eigennumbers/vectors\n",
    "If = np.where(np.cumsum(w_ext)/np.sum(w_ext)>0.8)[0][0] #Index of retained time extended eigenvalues\n",
    "print('The number of modes retained is '+str(If))\n",
    "v_ext = v_ext.real\n",
    "v_ext = v_ext[:,:If] #Define the number of EOFs retained \n",
    "\n",
    "errormaps = np.zeros((v.shape[0],nleads,nretained)) #Create empty array that contains the spatial-lead distribution of the leading 200 eigenmodes\n",
    "for modenum in np.arange(np.min((If,nretained))):\n",
    "    for lead in np.arange(nleads):\n",
    "        errormaps[:,lead,modenum]=v[:,:int(I80s[lead])].dot(v_ext[N[lead]:N[lead+1],modenum]) #Fill errormaps according to retained eigenmodes and lead\n",
    "\n",
    "    errormapslatlon = np.zeros((latitude,longitude,nleads)) #Create empty array that will house errormaps data in a latitude longitude grid\n",
    "    levs=np.arange(-0.02,0.022,.002) #Define levels for EOF loadings in future contour plot\n",
    "#    plt.figure(figsize = (9,5))\n",
    "    # lons = np.arange(0,358,2)\n",
    "    # lats = np.arange(-89,89,2)\n",
    "    plt.figure(figsize=(10,7)) #Define Figure\n",
    "\n",
    "    res = '50m'\n",
    "    \n",
    "    print('Modenum = '+str(modenum))\n",
    "    for y in np.arange(latitude):\n",
    "        errormapslatlon[y,:,:]=errormaps[y*179:(y+1)*179,:,modenum] #Fill errormapslatlon with data from the leading 6 eigenmodes (3 leading EOF pairs) \n",
    "        \n",
    "    #To plot map convert errormapslatlon to xarray. Define the 2 degree global domain\n",
    "    # lats = np.arange(-89,89,2)\n",
    "    # lons = np.arange(0,358,2)\n",
    "    # lead = np.arange(nleads)\n",
    "        \n",
    "    #Convert from numpy to xarray\n",
    "    errormapslatlon = xr.DataArray(errormapslatlon, coords=[lats, lons, leads], dims=[\"latitude\", \"longitude\", \"lead\"])    \n",
    "        \n",
    "    #Define the grid to make cyclic point\n",
    "    # dx = np.abs((lons[2]-lons[0]))\n",
    "    # dy = np.abs((lats[2]-lats[0]))\n",
    "    # dx, dy\n",
    "\n",
    "    # lonRange = np.arange(lonW, lonE + dx, dx)\n",
    "    # latRange = np.arange(latS, latN + dy, dy)\n",
    "\n",
    "    #proj_map = ccrs.PlateCarree(central_longitude=0)\n",
    "        \n",
    "    #Define regular grid from xarray errormapslatlon\n",
    "    grid_Reg1 = errormapslatlon.sel(longitude = lonRange, latitude = latRange, method = 'nearest')\n",
    "    lonsReg, latsReg = grid_Reg1.longitude, grid_Reg1.latitude\n",
    "\n",
    "#Create Plots for each lead    \n",
    "    for lead in np.arange(nleads):\n",
    "        plt.clf()\n",
    "        ax = plt.subplot(1,1,1, projection = ccrs.PlateCarree())\n",
    "        ax.set_global()\n",
    "        ax.coastlines()\n",
    "        \n",
    "        #Add Cyclic Point to regular grid by creating adjusted array grid_2d_1 which wraps an additional longitude datapoint on the Prime Meridian\n",
    "        grid_2d_1, clons = cutil.add_cyclic_point(grid_Reg1.isel(lead = lead), lonsReg)\n",
    "    \n",
    "        #Add title\n",
    "        title1 = str('Mode '+str(modenum+1)+' Lead '+str(lead+1))\n",
    "        ax.set_title(title1, fontsize = 12)\n",
    "        \n",
    "        #Make the plots\n",
    "        mm = ax.contourf(clons,latsReg, grid_2d_1, levels = levs, extend = 'both', transform = proj_map, cmap = 'bwr')\n",
    "        ax.set_extent([np.min(lons),np.max(lons), np.min(lats), np.max(lats)], crs = ccrs.PlateCarree())\n",
    "        ax.gridlines(crs=ccrs.PlateCarree(), draw_labels = True, linewidth = 2, color = 'gray', alpha = 0.5, linestyle = '--')\n",
    "#Save figures in the appropriate path:\n",
    "        plt.savefig('/free2/sm957448/will_files/200mb_Z/transfer_code_testing/eigenmode_plots/month_'+str(monthi)+'_eof'+str(modenum+1)+'_'+str(lead+1)+'.png')\n",
    "    print('Done with figures, creating reconstructions')   \n",
    "\n",
    "#Plots have been created for every lead of the leading 6 eigenmodes for a given month, illustrating the evolution of error patterns with lead. Now we move on to creating the reconstructions of the error anomalies\n",
    "\n",
    "#CREATE RECONSTRUCTIONS\n",
    "#Take 80% of the time extended variance (64% of variance for the total dataset)\n",
    "I80_ext = np.where(np.cumsum(w_ext)>.8)[0][0]\n",
    "\n",
    "#Create the time extended PCs from the time ext array\n",
    "PC_ext = X_ext.dot(v_ext[:,:int(I80_ext)]) #Project time extended eigenvectors onto training data to create time-extended PCs\n",
    "PC_ext20_a = X_ext20_a.dot(v_ext[:,:int(I80_ext)]) #Project time extended eigenvectors onto testing data to create time-extended PCs\n",
    "    \n",
    "#Now that we have the time extended EOFs and PCs, we can create the reconstructed error values for projection:\n",
    "time_ext_recon = PC_ext20_a.dot(v_ext[:,:I80_ext].T) #Define time extended reconstructions\n",
    "error_recon = np.zeros((Xmonths20_a.shape[0], Xmonths20_a.shape[1],nleads)) #Define spatial reconstructions\n",
    "for lead in np.arange(nleads): #Create spatial reconstructions by projecting time extended PC based reconstructions onto spatial EOfs\n",
    "    error_recon[:,:,lead] = time_ext_recon[:,I80s_cum[lead]:I80s_cum[lead+1]].dot(v[:,:int(I80s[lead])].T)\n",
    "\n",
    "#Convert the spatial reconstructed error array into an array which accounts for latitude and longitude\n",
    "error_reconll = np.zeros((error_recon.shape[0],gefs_data.shape[1],gefs_data.shape[2],nleads)) #Define spatial reconstructions in latitude and longitude format\n",
    "for y in np.arange(latitude): #Convert spatial reconstructions into latitude and longitude format\n",
    "    error_reconll[:,y,:,:] = error_recon[:,y*longitude:(y+1)*longitude,:]\n",
    "print('Reconstruction for month '+str(monthi)+' complete. Saving reconstruction')\n",
    " \n",
    "#Save the reconstructions for the given month. Code will now move onto the next month\n",
    "np.save('/free2/sm957448/will_files/200mb_Z/transfer_code_testing/error_reconll_'+str(monthi)+'.npy', error_reconll) #Define globally at the top for all paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04d4a3b6-7b47-4c91-99f6-96c40448da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting seasonal cycle of error\n",
      "Plotting seasonal cycle of error\n",
      "Plotting seasonal cycle of error\n",
      "Plotting seasonal cycle of error\n",
      "Plotting seasonal cycle of error\n",
      "Plotting seasonal cycle of error\n",
      "Plotting seasonal cycle of error\n",
      "Plotting seasonal cycle of error\n",
      "Plotting seasonal cycle of error\n",
      "Plotting seasonal cycle of error\n",
      "Plotting seasonal cycle of error\n",
      "Plotting seasonal cycle of error\n",
      "Plotting seasonal cycle of error\n",
      "Plotting seasonal cycle of error\n",
      "Plotting seasonal cycle of error\n",
      "Plotting seasonal cycle of error\n"
     ]
    }
   ],
   "source": [
    "# Revise to load climatologically data to make climatology plots\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "from scipy import io as io\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeat\n",
    "import pygrib\n",
    "import urllib\n",
    "import ftplib\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "from cartopy import crs as ccrs, feature as cfeature\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.util as cutil\n",
    "\n",
    "#SPACIAL DEFININTIONS\n",
    "latS = -88\n",
    "latN = 88\n",
    "lonW = 0\n",
    "lonE = 356\n",
    "clons = (lonW+lonE)/2.\n",
    "nleads = 16\n",
    "time = np.arange(365)\n",
    "lats = np.arange(-89,89,2)\n",
    "lons = np.arange(0,358,2)\n",
    "lead = np.arange(nleads)\n",
    "dx = np.abs((lons[2]-lons[0]))\n",
    "dy = np.abs((lats[2]-lats[0]))\n",
    "dx, dy\n",
    "proj_map = ccrs.PlateCarree(central_longitude=0)\n",
    "lonRange = np.arange(lonW, lonE + dx, dx)\n",
    "latRange = np.arange(latS, latN + dy, dy)\n",
    "I = np.arange(365)#Create indexing for one year of data\n",
    "fig = plt.figure(figsize = (8.5,11))\n",
    "fig.tight_layout()\n",
    "\n",
    "ecclimo = np.load('/free2/sm957448/will_files/200mb_Z/ecclimo/ecclimo.npy')\n",
    "for lead in np.arange(nleads):\n",
    "    gefsclimo=np.load('/free2/sm957448/will_files/200mb_Z/gefs_climo/gefs_climo_lead'+str(lead)+'.npy') #Loads saved gefs_climo files as a .npy\n",
    "    #cycle = np.zeros((365,gefsclimo.shape[1],gefsclimo.shape[2])) #Define seasonal cycle array\n",
    "    \n",
    "    cycle[I,:,:] = gefsclimo[I,:,:]-ecclimo[I+lead,:,:] #fill seasonal cycle array by subtracting the two climatologies\n",
    "    if lead == 0: #Seasonal cycle of error does not include initial condition errors. Remove lead 1 errors by subtracting from cycle\n",
    "        cyc_0 = cycle[I,:,:]\n",
    "        cycle[I,:,:] == 0\n",
    "    cycle[I,:,:] = cycle[I,:,:]-cyc_0 #Subtract lead 1 errors\n",
    "    print('Plotting seasonal cycle of error')\n",
    "\n",
    "    cycle = xr.DataArray(cycle, coords=[time,lats, lons], dims=[\"time\",\"latitude\", \"longitude\"])\n",
    "\n",
    "    #Specify Grids\n",
    "    grid_Reg1 = cycle.sel(longitude = lonRange, latitude = latRange, method = 'nearest')\n",
    "    lonsReg, latsReg = grid_Reg1.longitude, grid_Reg1.latitude\n",
    "\n",
    "    #Define levels in decameters\n",
    "    cycleLevels = np.arange(-10,11,1)\n",
    "\n",
    "    #define resolution\n",
    "    res = '50m'\n",
    "\n",
    "    day_inc = np.arange(1)\n",
    "    #PLOT Model Seasonal Cycle of Error\n",
    "    for day in np.arange(0,365,10):#modify day_inc to find days you would like to assess the seasonal cycle of\n",
    "        #For increments, replace day_inc in the np.arange with the proper increments\n",
    "        #for lead in np.arange(nleads):\n",
    "        plt.clf()\n",
    "        ax = fig.add_subplot(1,1,1, projection = proj_map)\n",
    "        ax.add_feature(cfeature.COASTLINE.with_scale(res), lw=1)\n",
    "\n",
    "        #Add Cyclic Point\n",
    "        grid_2d_1, clons = cutil.add_cyclic_point(grid_Reg1, lonsReg)\n",
    "    \n",
    "        #Add title\n",
    "        title1 = str('200 hPa Geopotential Height Seasonal Cycle of Error \\n DOY = '+str(day)+', Lead = '+str(lead))\n",
    "        ax.set_title(title1)\n",
    "\n",
    "        #Contour fills\n",
    "        SS = ax.contourf(clons, latsReg, grid_2d_1[day,:,:], levels = cycleLevels, cmap = 'bwr', extend = 'both', transform = proj_map)\n",
    "        cbar = fig.colorbar(SS,shrink=0.5, orientation = 'horizontal', pad = 0.01)\n",
    "        # fontsize_cbar_tick = 9 \n",
    "        # cbar.ax.tick_params(labelsize=fontsize_cbar_tick)\n",
    "        cbar.set_label('Error Anomalies (dam)')\n",
    "        \n",
    "        plt.savefig('/free2/sm957448/will_files/200mb_Z/transfer_code_testing/climo_d'+str(day)+'_l'+str(lead)+'.png')\n",
    "# MODE MONTH LEAD INDEXES\n",
    "# ANIMATIONS\n",
    "#PUBLIC HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b2a8d31-6b06-4af9-b12e-f7994b153752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282399.1315552432\n"
     ]
    }
   ],
   "source": [
    "#plt.plot(gefs_data[:,50,50])\n",
    "\n",
    "\n",
    "#plt.savefig('/free2/sm957448/will_files/200mb_Z/transfer_code/plots/plots.png')\n",
    "print(np.sum(gefs_data)/ngrids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 August 2022 Environment",
   "language": "python",
   "name": "aug22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
